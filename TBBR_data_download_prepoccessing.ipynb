{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Xyzzwycpb2by"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6prpLzo_5hZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycocotools"
      ],
      "metadata": {
        "id": "9frx9_clH4al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "p8IBpFuYH_Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pycocotools.coco import COCO\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import random\n"
      ],
      "metadata": {
        "id": "zl9bN2ydJAb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#initial setup\n"
      ],
      "metadata": {
        "id": "Xyzzwycpb2by"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#After downloading the zip files of the ikages from the dataset, this code just helps is unpavking all of them and the json file ofr annoatations."
      ],
      "metadata": {
        "id": "MR-sjAMXLYQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/TBBR"
      ],
      "metadata": {
        "id": "K2VSF6pa5qDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iLjaD7K4PYHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "get annotations"
      ],
      "metadata": {
        "id": "VBd8yZz1PYy-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voRLezSv3xl-"
      },
      "outputs": [],
      "source": [
        "#!wget -r https://zenodo.org/records/7022736/files/Flug1_100-104Media_coco.json?download=1 -P /content/drive/MyDrive/TBBR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip /content/drive/MyDrive/TBBR/zenodo.org/records/7360996/files/Flug_100.zip?download=1 -d /content/drive/MyDrive/TBBR"
      ],
      "metadata": {
        "id": "Qjq6XloLI-bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_json\n",
        "with open('/content/drive/MyDrive/TBBR/train/Flug1_100-104Media_coco.json', 'r') as f:\n",
        "  data = json.load(f)\n",
        "\n"
      ],
      "metadata": {
        "id": "vWmqBXJDJAey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y0G6FM-7zy36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TYsnSEsDPU6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "extract the images"
      ],
      "metadata": {
        "id": "oS7NKNi0PVZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y zstd"
      ],
      "metadata": {
        "id": "KnxTVcI_zv9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zstd -d /content/drive/MyDrive/TBBR/train/Flug1_100.tar.zst --stdout | tar -xvf - -C /content/drive/MyDrive/TBBR/train"
      ],
      "metadata": {
        "id": "e911qN6zwCM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XtzCa4bOwCVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "separate annotation of firts 100"
      ],
      "metadata": {
        "id": "mmpqNvDqPNQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dont run\n",
        "import json\n",
        "\n",
        "# Load the JSON file\n",
        "input_file_path = '/content/drive/MyDrive/TBBR/train/Flug1_100-104Media_coco.json'  # Replace with the actual path to your JSON file\n",
        "output_file_path = '/content/drive/MyDrive/TBBR/train/Flug1_100Media_coco.json'  # Output file name\n",
        "\n",
        "# Read the data from the original JSON file\n",
        "with open(input_file_path, 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Step 1: Filter images to include only those that belong to Flug1_100\n",
        "flug100_images = [img for img in data.get(\"images\", []) if 'Flug1_100/' in img.get(\"file_name\", \"\")]\n",
        "\n",
        "# Step 2: Get the image IDs for Flug1_100 images\n",
        "flug100_image_ids = {img[\"id\"] for img in flug100_images}\n",
        "\n",
        "# Step 3: Filter annotations that correspond to Flug1_100 images\n",
        "flug100_annotations = [ann for ann in data.get(\"annotations\", []) if ann[\"image_id\"] in flug100_image_ids]\n",
        "\n",
        "# Step 4: Prepare the new JSON data structure with filtered images, annotations, and original categories\n",
        "filtered_data = {\n",
        "    \"images\": flug100_images,\n",
        "    \"annotations\": flug100_annotations,\n",
        "    \"categories\": data.get(\"categories\", [])  # Categories can be kept as they are\n",
        "}\n",
        "\n",
        "# Step 5: Save the filtered data to a new JSON file\n",
        "with open(output_file_path, 'w') as output_file:\n",
        "    json.dump(filtered_data, output_file)\n",
        "\n",
        "print(f\"Filtered JSON file saved to {output_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QU2dBML-WK_",
        "outputId": "8683aad8-4fad-41a8-aab2-354a121c8394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered JSON file saved to /content/drive/MyDrive/TBBR/train/Flug1_100Media_coco.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#visualization"
      ],
      "metadata": {
        "id": "HZJEMnGrcAEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/TBBR/train/Flug1_100Media_coco.json', 'r') as f:\n",
        "  data1 = json.load(f)\n"
      ],
      "metadata": {
        "id": "yhMeGTGY-hoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data1)"
      ],
      "metadata": {
        "id": "wn5n_seF-kov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/drive/MyDrive/TBBR/train/images/Flug1_100/DJI_0055_R.npy\"  # Replace with your file path\n",
        "image = np.load(image_path)  # Shape: (2680, 3370, 5)\n",
        "print(f\"Number of channels: {image.shape[2]}\")\n",
        "\n",
        "# Extract RGB (BGR) channels and convert to RGB format\n",
        "b_channel = image[:, :, 0]\n",
        "g_channel = image[:, :, 1]\n",
        "r_channel = image[:, :, 2]\n",
        "\n",
        "# Stack to form an RGB image (H, W, 3)\n",
        "rgb_image = np.stack([r_channel, g_channel, b_channel], axis=-1)\n",
        "\n",
        "# Normalize RGB image (if pixel values > 1)\n",
        "rgb_image = rgb_image / np.max(rgb_image)\n",
        "\n",
        "# Extract the Thermal channel\n",
        "thermal_image = image[:, :, 3]  # Thermal is the 4th channel\n",
        "\n",
        "# Normalize the thermal image for better visualization\n",
        "thermal_image_normalized = (thermal_image - np.min(thermal_image)) / (np.max(thermal_image) - np.min(thermal_image))\n",
        "\n",
        "\n",
        "#depth channel\n",
        "depth_image = image[:, :, 4]\n",
        "depth_image_normalized = (depth_image - np.min(depth_image)) / (np.max(depth_image) - np.min(depth_image))\n",
        "\n",
        "# Plot the RGB and Thermal images\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Plot RGB image\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(rgb_image)\n",
        "plt.title('RGB Image')\n",
        "plt.axis('off')\n",
        "\n",
        "# Plot Thermal image\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(thermal_image_normalized, cmap='hot')  # Use 'hot' for thermal visualization\n",
        "plt.title('Thermal Image')\n",
        "plt.axis('off')\n",
        "\n",
        "#depth\n",
        "# Plot Depth image\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(depth_image_normalized, cmap='viridis')  # 'viridis' is good for depth visualization\n",
        "plt.title('Depth Image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-_Yl2GiCroJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the COCO JSON file\n",
        "annotation_file = \"/content/drive/MyDrive/TBBR/train/Flug1_100Media_coco.json\"\n",
        "coco = COCO(annotation_file)\n",
        "\n",
        "\n",
        "\n",
        "# Select an image by its ID (pick the first one as an example)\n",
        "image_id = list(coco.imgs.keys())[4]  # Replace with desired image ID\n",
        "image_info = coco.loadImgs(image_id)[0]\n",
        "\n",
        "\n",
        "\n",
        "# Load the corresponding .npy image\n",
        "image_path = f\"/content/drive/MyDrive/TBBR/train/images/{image_info['file_name']}\"  # Adjust path as needed\n",
        "image = np.load(image_path)  # Shape: (2680, 3370, 5)\n",
        "\n",
        "# Extract RGB channels\n",
        "b_channel, g_channel, r_channel = image[:, :, 0], image[:, :, 1], image[:, :, 2]\n",
        "rgb_image = np.stack([r_channel, g_channel, b_channel], axis=-1) / np.max(image[:, :, :3])\n",
        "\n",
        "thermal_image = image[:, :, 3]\n",
        "\n",
        "# Normalize the Thermal channel for visualization\n",
        "thermal_image_normalized = (thermal_image - np.min(thermal_image)) / (np.max(thermal_image) - np.min(thermal_image))\n",
        "\n",
        "# Get annotations for the image\n",
        "ann_ids = coco.getAnnIds(imgIds=image_id)\n",
        "annotations = coco.loadAnns(ann_ids)\n",
        "\n",
        "# Plot the image with annotations\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(thermal_image_normalized)\n",
        "plt.axis('off')\n",
        "\n",
        "# Overlay annotations\n",
        "for ann in annotations:\n",
        "    # Draw bounding box (if present)\n",
        "    if 'bbox' in ann:\n",
        "        x, y, w, h = ann['bbox']\n",
        "        plt.gca().add_patch(plt.Rectangle((x, y), w, h, edgecolor='red', facecolor='none', lw=2))\n",
        "\n",
        "    # Draw segmentation mask (if present)\n",
        "    if 'segmentation' in ann:\n",
        "        for seg in ann['segmentation']:\n",
        "            seg_np = np.array(seg).reshape(-1, 2)\n",
        "            plt.gca().add_patch(plt.Polygon(seg_np, color='blue', alpha=0.3))\n",
        "\n",
        "plt.title(f\"Image ID: {image_id} with Annotations\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d1CRQjy2roL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#preprocessing"
      ],
      "metadata": {
        "id": "A7u88bF48soz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dont run\n",
        "# Load annotations\n",
        "annotation_path = \"/content/drive/MyDrive/TBBR/train/Flug1_100Media_coco.json\"\n",
        "with open(annotation_path, 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# Augmentation Functions\n",
        "def random_flip(image, annotations, flip_prob=0.5):\n",
        "    \"\"\"Randomly flips an image horizontally and adjusts annotations.\"\"\"\n",
        "    if random.random() < flip_prob:\n",
        "        # Flip image horizontally\n",
        "        image = np.flip(image, axis=1).copy()\n",
        "\n",
        "        # Adjust bounding boxes\n",
        "        for ann in annotations:\n",
        "            x, y, w, h = ann['bbox']\n",
        "            ann['bbox'][0] = image.shape[1] - x - w\n",
        "\n",
        "        # Adjust segmentation masks\n",
        "        for ann in annotations:\n",
        "            if 'segmentation' in ann:\n",
        "                for seg in ann['segmentation']:\n",
        "                    for i in range(0, len(seg), 2):\n",
        "                        seg[i] = image.shape[1] - seg[i]\n",
        "\n",
        "    return image, annotations\n",
        "\n",
        "\n",
        "# Process each image\n",
        "for img_info in tqdm(coco_data['images']):\n",
        "    image_path = f\"/content/drive/MyDrive/TBBR/train/images/{img_info['file_name']}\"\n",
        "    image = np.load(image_path)\n",
        "\n",
        "    #denoising\n",
        "    image[:, :, 3] = cv2.GaussianBlur(image[:, :, 3], (5, 5), 0)\n",
        "\n",
        "\n",
        "    # Normalize\n",
        "    for i in range(5):  # Normalize all channels\n",
        "        image[:, :, i] = (image[:, :, i] - image[:, :, i].min()) / (image[:, :, i].max() - image[:, :, i].min())\n",
        "\n",
        "    # Get annotations for this image\n",
        "    annotations = [ann for ann in coco_data['annotations'] if ann['image_id'] == img_info['id']]\n",
        "\n",
        "    # Apply augmentations\n",
        "    image, annotations = random_flip(image, annotations)\n",
        "\n",
        "\n",
        "    # Resize (optional)\n",
        "    scale_x = 0.5\n",
        "    scale_y = 0.5\n",
        "    resized_image = cv2.resize(image, (int(image.shape[1] * scale_x), int(image.shape[0] * scale_y)))\n",
        "\n",
        "    # Update annotations\n",
        "    for ann in coco_data['annotations']:\n",
        "        if ann['image_id'] == img_info['id']:\n",
        "            x, y, w, h = ann['bbox']\n",
        "            ann['bbox'] = [x * scale_x, y * scale_y, w * scale_x, h * scale_y]\n",
        "\n",
        "            if 'segmentation' in ann:\n",
        "                ann['segmentation'] = [[coord * scale_x if i % 2 == 0 else coord * scale_y for i, coord in enumerate(seg)] for seg in ann['segmentation']]\n",
        "\n",
        "    # Save augmented and preprocessed image\n",
        "    np.save(f\"/content/drive/MyDrive/TBBR/train/images/{img_info['file_name']}\", image)\n",
        "\n",
        "\n",
        "\n",
        "# Save updated annotations\n",
        "with open(\"/content/drive/MyDrive/TBBR/train/Flug1_100Media_coco.json\", 'w') as f:\n",
        "    json.dump(coco_data, f)\n"
      ],
      "metadata": {
        "id": "j7gy88xDroRo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}